{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0804 23:03:46.708648 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0804 23:03:46.740650 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0804 23:03:46.792653 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0804 23:03:46.876658 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0804 23:03:46.881658 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0804 23:03:46.976664 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0804 23:03:47.173675 18380 deprecation_wrapper.py:119] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0804 23:03:47.570698 18380 deprecation.py:323] From c:\\users\\hasee\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2698 - acc: 0.9264\n",
      "\n",
      "Testing ------------\n",
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "\n",
      "test loss:  0.10120071786083282\n",
      "\n",
      "test accuracy:  0.9687\n"
     ]
    }
   ],
   "source": [
    "# CNN example\n",
    "\n",
    "# to try tensorflow, un-comment following two lines\n",
    "# import os\n",
    "# os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# download the mnist to the path '~/.keras/datasets/' if it is the first time to be called\n",
    "# training X shape (60000, 28x28), Y shape (60000, ). test X shape (10000, 28x28), Y shape (10000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# data pre-processing\n",
    "X_train = X_train.reshape(-1, 1,28, 28)/255. # -1是样本数量，但不知道有多少，可以用-1代替，可以理解为缺省值\n",
    "X_test = X_test.reshape(-1, 1,28, 28)/255. # 黑白照1,28x28照片\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10) # 3.6版本要将np_classes改为num_classes\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Another way to build your CNN\n",
    "model = Sequential()\n",
    "\n",
    "# Conv layer 1 output shape (32, 28, 28)\n",
    "model.add(Convolution2D(\n",
    "    batch_input_shape=(None, 1, 28, 28),\n",
    "    filters=32, # 滤波器就是卷积核 ，32就是32张不同feature的图片，feature map\n",
    "    kernel_size=5,\n",
    "    strides=1,\n",
    "    padding='same',     # Padding method\n",
    "    data_format='channels_first',\n",
    "))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 1 (max pooling) output shape (32, 14, 14)\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=2, # 取样多长多宽的图片\n",
    "    strides=2, # 步长，跳几个pixel\n",
    "    padding='same',    # Padding method ，same 长宽都一样，不跳\n",
    "    data_format='channels_first',\n",
    "))\n",
    "\n",
    "# Conv layer 2 output shape (64, 14, 14)\n",
    "model.add(Convolution2D(64, 5, strides=1, padding='same', data_format='channels_first'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling layer 2 (max pooling) output shape (64, 7, 7)\n",
    "model.add(MaxPooling2D(2, 2, 'same', data_format='channels_first'))\n",
    "\n",
    "# Fully connected layer 1 input shape (64 * 7 * 7) = (3136), output shape (1024) \n",
    "# 全连接层\n",
    "model.add(Flatten()) # 三维磨成一维的\n",
    "model.add(Dense(1024))# 1024神经元个数，代表这一层你想要多少神经元（即数据的维度）\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Fully connected layer 2 to shape (10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Another way to define your optimizer\n",
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "# We add metrics to get more results you want to see\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Training ------------')\n",
    "# Another way to train the model\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=64,)\n",
    "\n",
    "print('\\nTesting ------------')\n",
    "# Evaluate the model with the metrics we defined earlier\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('\\ntest loss: ', loss)\n",
    "print('\\ntest accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
